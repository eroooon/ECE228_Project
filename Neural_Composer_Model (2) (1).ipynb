{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydot==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install graphviz==0.10.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-pydot python-pydot-ng graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theano Version: 1.0.5\n",
      "Keras Version: 2.4.3\n",
      "Tensorflow Version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#import midi\n",
    "import numpy as np\n",
    "import math\n",
    "import sys, random, os\n",
    "from matplotlib import pyplot as plt\n",
    "import pydot\n",
    "import keras\n",
    "import theano\n",
    "\n",
    "\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Reshape, Permute, RepeatVector, ActivityRegularization, TimeDistributed, Lambda, SpatialDropout1D\n",
    "from keras.layers.convolutional import Conv1D, Conv2D, Conv2DTranspose, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.local import LocallyConnected2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "print (\"Theano Version: \" + theano.__version__)\n",
    "print (\"Keras Version: \" + keras.__version__)\n",
    "print (\"Tensorflow Version: \" + tf.__version__)\n",
    "\n",
    "#from tensorflow.python.keras import backend as K\n",
    "#config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "#sess = tf.compat.v1.Session(config=config) \n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "NUM_EPOCHS = 100\n",
    "LR = 0.001\n",
    "CONTINUE_TRAIN = False\n",
    "PLAY_ONLY = False\n",
    "USE_EMBEDDING = False\n",
    "USE_VAE = False\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "WRITE_HISTORY = True\n",
    "NUM_RAND_SONGS = 10\n",
    "DO_RATE = 0.1\n",
    "BN_M = 0.9\n",
    "VAE_B1 = 0.02\n",
    "VAE_B2 = 0.1\n",
    "\n",
    "BATCH_SIZE = 350\n",
    "MAX_LENGTH = 16\n",
    "PARAM_SIZE = 120\n",
    "NUM_OFFSETS = 16 if USE_EMBEDDING else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility functions ##\n",
    "# 16 measures set for each song\n",
    "\n",
    "def transpose_range(samples):\n",
    "    merged_sample = np.zeros_like(samples[0])\n",
    "    for sample in samples:\n",
    "        merged_sample = np.maximum(merged_sample, sample)\n",
    "    merged_sample = np.amax(merged_sample, axis=0)\n",
    "    min_note = np.argmax(merged_sample)\n",
    "    max_note = merged_sample.shape[0] - np.argmax(merged_sample[::-1])\n",
    "    return min_note, max_note\n",
    "\n",
    "def generate_add_centered_transpose(samples):\n",
    "    num_notes = samples[0].shape[1]\n",
    "    min_note, max_note = transpose_range(samples)\n",
    "    s = num_notes/2 - (max_note + min_note)/2\n",
    "    out_samples = samples\n",
    "    out_lens = [len(samples), len(samples)]\n",
    "    for i in range(len(samples)):\n",
    "        out_sample = np.zeros_like(samples[i])\n",
    "        out_sample[:,int(min_note+s):int(max_note+s)] = samples[i][:,min_note:max_note]\n",
    "        out_samples.append(out_sample)\n",
    "    return out_samples, out_lens\n",
    "\n",
    "def generate_all_transpose(samples, radius=6):\n",
    "    num_notes = samples[0].shape[1]\n",
    "    min_note, max_note = transpose_range(samples)\n",
    "    min_shift = -min(radius, min_note)\n",
    "    max_shift = min(radius, num_notes - max_note)\n",
    "    out_samples = []\n",
    "    out_lens = []\n",
    "    for s in range(min_shift, max_shift):\n",
    "        for i in range(len(samples)):\n",
    "            out_sample = np.zeros_like(samples[i])\n",
    "            out_sample[:,min_note+s:max_note+s] = samples[i][:,min_note:max_note]\n",
    "            out_samples.append(out_sample)\n",
    "        out_lens.append(len(samples))\n",
    "    return out_samples, out_lens\n",
    "\n",
    "def sample_to_pic(fname, sample, thresh=None):\n",
    "    if thresh is not None:\n",
    "        inverted = np.where(sample > thresh, 0, 1)\n",
    "    else:\n",
    "        inverted = 1.0 - sample\n",
    "    cv2.imwrite(fname, inverted * 255)\n",
    "\n",
    "def samples_to_pics(dir, samples, thresh=None):\n",
    "    if not os.path.exists(dir): os.makedirs(dir)\n",
    "    for i in range(samples.shape[0]):\n",
    "        sample_to_pic(dir + '/s' + str(i) + '.png', samples[i], thresh)\n",
    "\n",
    "def pad_songs(y, y_lens, max_len):\n",
    "    y_shape = (y_lens.shape[0], max_len) + y.shape[1:]\n",
    "    y_train = np.zeros(y_shape, dtype=np.float32)\n",
    "    cur_ix = 0\n",
    "    for i in range(y_lens.shape[0]):\n",
    "        end_ix = cur_ix + y_lens[i]\n",
    "        for j in range(max_len):\n",
    "            k = j % (end_ix - cur_ix)\n",
    "            y_train[i,j] = y[cur_ix + k]\n",
    "        cur_ix = end_ix\n",
    "    assert(end_ix == y.shape[0])\n",
    "    return y_train\n",
    "\n",
    "def sample_to_pattern(sample, ix, size):\n",
    "    num_pats = 0\n",
    "    pat_types = {}\n",
    "    pat_list = []\n",
    "    num_samples = len(sample) if type(sample) is list else sample.shape[0]\n",
    "    for i in range(size):\n",
    "        j = (ix + i) % num_samples\n",
    "        measure = sample[j].tobytes()\n",
    "        if measure not in pat_types:\n",
    "            pat_types[measure] = num_pats\n",
    "            num_pats += 1\n",
    "        pat_list.append(pat_types[measure])\n",
    "    return str(pat_list), pat_types\n",
    "\n",
    "def embed_samples(samples):\n",
    "    note_dict = {}\n",
    "    n, m, p = samples.shape\n",
    "    samples.flags.writeable = False\n",
    "    e_samples = np.empty(samples.shape[:2], dtype=np.int32)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            note = samples[i,j].data\n",
    "            if note not in note_dict:\n",
    "                note_dict[note] = len(note_dict)\n",
    "            e_samples[i,j] = note_dict[note]\n",
    "    samples.flags.writeable = True\n",
    "    lookup = np.empty((len(note_dict), p), dtype=np.float32)\n",
    "    for k in note_dict:\n",
    "        lookup[note_dict[k]] = k\n",
    "    return e_samples, note_dict, lookup\n",
    "\n",
    "def e_to_samples(e_samples, lookup):\n",
    "    samples = np.empty(e_samples.shape + lookup.shape[-1:], dtype=np.float32)\n",
    "    n, m = e_samples.shape\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            samples[i,j] = lookup[e_samples[i,j]]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_notes = 96\n",
    "samples_per_measure = 96\n",
    "\n",
    "def midi_to_samples(fname):\n",
    "    has_time_sig = False\n",
    "    flag_warning = False\n",
    "    mid = MidiFile(fname)\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "    ticks_per_measure = 4 * ticks_per_beat\n",
    "\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        for msg in track:\n",
    "            if msg.type == 'time_signature':\n",
    "                new_tpm = msg.numerator * ticks_per_beat * 4 / msg.denominator\n",
    "                if has_time_sig and new_tpm != ticks_per_measure:\n",
    "                    flag_warning = True\n",
    "                ticks_per_measure = new_tpm\n",
    "                has_time_sig = True\n",
    "    if flag_warning:\n",
    "#         print (\"  ^^^^^^ WARNING ^^^^^^ \" )\n",
    "        return []\n",
    "    all_notes = {}\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        abs_time = 0\n",
    "        for msg in track:\n",
    "            abs_time += msg.time\n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity == 0:\n",
    "                    continue\n",
    "                note = msg.note - (128 - num_notes)/2\n",
    "                assert(note >= 0 and note < num_notes)\n",
    "                if note not in all_notes:\n",
    "                    all_notes[note] = []\n",
    "                else:\n",
    "                    single_note = all_notes[note][-1]\n",
    "                    if len(single_note) == 1:\n",
    "                        single_note.append(single_note[0] + 1)\n",
    "                all_notes[note].append([abs_time * samples_per_measure / ticks_per_measure])\n",
    "            elif msg.type == 'note_off':\n",
    "                if len(all_notes[note][-1]) != 1:\n",
    "                    continue\n",
    "                all_notes[note][-1].append(abs_time * samples_per_measure / ticks_per_measure)    \n",
    "    for note in all_notes:\n",
    "        for start_end in all_notes[note]:\n",
    "            if len(start_end) == 1:\n",
    "                start_end.append(start_end[0] + 1)\n",
    "    samples = []\n",
    "    for note in all_notes:\n",
    "        for start, end in all_notes[note]:\n",
    "            sample_ix = start / samples_per_measure\n",
    "            while len(samples) <= sample_ix:\n",
    "                samples.append(np.zeros((samples_per_measure, num_notes), dtype=np.uint8))\n",
    "            sample = samples[int(sample_ix)]\n",
    "            start_ix = start - sample_ix * samples_per_measure        \n",
    "            if False:\n",
    "                end_ix = min(end - sample_ix * samples_per_measure, samples_per_measure)\n",
    "                while start_ix < end_ix:\n",
    "                    sample[int(start_ix), int(note)] = 1\n",
    "                    start_ix += 1\n",
    "            else:\n",
    "                sample[int(start_ix), int(note)] = 1 \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Songs...\n",
      "Saving data/Midi/2a60530c7dccc812f5b8acaed9ade9ed.mid\n",
      "Saving data/Midi/c1570bd149d3b8e63e45be58552fea19.mid\n",
      "Saving data/Midi/0d15ccb09ec9efa67f933ec37c56c5eb.mid\n",
      "ERROR  data/Midi/3268d19b81145078d1a8f450feb07d7b.mid \n",
      "ERROR  data/Midi/a478302cafde2aa91b28e57cae9efea7.mid \n",
      "Saving data/Midi/7daacb647e8968e7422d59912f8153fd.mid\n",
      "Saving data/Midi/3abdac41f329dda66f7963d47bb311aa.mid\n",
      "Saving data/Midi/b3873990c90cfd2a6fe3ae8040ecb0af.mid\n",
      "Saving data/Midi/56699e4a5f6343f56f0179ebfa6fc078.mid\n",
      "Saving data/Midi/b8e21a6a26ea481e0301463cd6311bf4.mid\n",
      "Saving data/Midi/587bf1c0c607b5b1566ff64dbfe8fc1c.mid\n",
      "ERROR  data/Midi/c94f0a7845a2bc9214693f8da9fa0452.mid \n",
      "Saving data/Midi/f660eb7e22599b36bb8a1b9f65036fb9.mid\n",
      "Saving data/Midi/5af385075eb2a03122a8b7d2a233c15e.mid\n",
      "Saving data/Midi/17f3df180d6788e8dcc617f02fa336fb.mid\n",
      "Saving data/Midi/9463536887c06cf31d8ed1407f886048.mid\n",
      "Saving data/Midi/24a4adfb3d307222884a9ab4718b3c3d.mid\n",
      "Saving data/Midi/36b668824f5477a016eb2eaaea59df56.mid\n",
      "Saving data/Midi/49a4d9293cd53d082a50c24a94084e97.mid\n",
      "Saving data/Midi/a99ea46d2c8c1793dc6eaecc446b266b.mid\n",
      "Saving data/Midi/bbbfc9a981637fad581f358efc864ddb.mid\n",
      "Saving data/Midi/cdea4fba7bb2cd8524c936fd596c396f.mid\n",
      "Saving data/Midi/21708c84ab988270095f942f38e39c90.mid\n",
      "Saving data/Midi/8384ad335fcd1a329234426edd4d59f7.mid\n",
      "Saving data/Midi/62787b8fe799beb99f1c785da105c47c.mid\n",
      "Saving data/Midi/c73ea34b903b4559d9d154e655a1d10b.mid\n",
      "Saving data/Midi/35ba5c5ffdac5fa05ef71c56e47e2e8e.mid\n",
      "Saving data/Midi/a22ce1ee1bb754f20526c60f4cbbdaba.mid\n",
      "Saving data/Midi/17bb81f1058a947fe5f9ab433e91a2c3.mid\n",
      "Saving data/Midi/345dc2e2c5e1a4c1f4185ca3a2ca9e10.mid\n",
      "Saving data/Midi/3fdccb655d1b8b825ebf4592187d1436.mid\n",
      "Saving data/Midi/f1ceaf439bc06f347a263173384c6567.mid\n",
      "Saving data/Midi/c3df9821f423de4fea20720ec83a4e54.mid\n",
      "Saving data/Midi/9fff5299040cfc6968a58a2c8cadda85.mid\n",
      "Saving data/Midi/cf319862f66e07e158a59a0e36100740.mid\n",
      "Saving data/Midi/e6b1f20fe5d5585f8727cf29aa494e5a.mid\n",
      "Saving data/Midi/87e5b0f4376e96e4724bd8ef4c6b8477.mid\n",
      "Saving data/Midi/b30c1573b025872a5f3e925555b782e3.mid\n",
      "Saving data/Midi/c3f6b4c34b76201b6327ef3ee06993b9.mid\n",
      "Saving data/Midi/a9b44a0e279782180495626ac59b9607.mid\n",
      "Saving data/Midi/99ab460a8a96bbcecca7f15e982cc94b.mid\n",
      "Saving data/Midi/569726fc28a4ad6ce7c1a2e4c9ab7d88.mid\n",
      "Saving data/Midi/23b2c12a051766cf2fbcadf3c1361e83.mid\n",
      "Saving data/Midi/724d1c04401a1aee3139f3a6665b1074.mid\n",
      "Saving data/Midi/6cadae094b3565481b6440626501628c.mid\n",
      "Saving data/Midi/ad77f62e662a5ec2951e7e0b085f6618.mid\n",
      "Saving data/Midi/794f3a522859b096b9f410b50263aac2.mid\n",
      "Saving data/Midi/5f549842038c319e3b64b217b4ab8548.mid\n",
      "Saving data/Midi/4730a435112c3a412405d0827df415d5.mid\n",
      "Saving data/Midi/898528b582b65949ed87be877d2cd26b.mid\n",
      "Saving data/Midi/970d4e02c3c6b40fc1725cf4fa795abd.mid\n",
      "Saving data/Midi/be0ac023f7673b5c5beed39ab2d3fa47.mid\n",
      "Saving data/Midi/20f50eab0cfe1ab4c55f34b36647ea7c.mid\n",
      "Saving data/Midi/d7151aa5f3a4a235f2a73c96677b31fb.mid\n",
      "Saving data/Midi/de4a2d5e8173e1c433002adb49e98868.mid\n",
      "Saving data/Midi/5a7197de78243f188dc6aba2f51aa5ab.mid\n",
      "Saving data/Midi/583fa7735d9714d88c1e640791e3e463.mid\n",
      "Saving data/Midi/eef4e7f05a5a480507e75ed37b5d1fc8.mid\n",
      "Saving data/Midi/45435b011a66b5491b0c880393a9cf93.mid\n",
      "Saving data/Midi/d883e4e642866904477579452df49c73.mid\n",
      "Saving data/Midi/5039f20fcd275f77a19580198e9f15a9.mid\n",
      "Saving data/Midi/e4b8b2a4835db807d8ac9e1b6f62b2cb.mid\n",
      "Saving data/Midi/060682abba44a99cbc89d0d0cc6649ab.mid\n",
      "Saving data/Midi/8ec686a8873bbfcdef557bd4e8501f77.mid\n",
      "ERROR  data/Midi/a379e0a8098f62613ed7d9e2a933d62f.mid \n",
      "Saving data/Midi/805803f370ef9158c6775487630bad81.mid\n",
      "Saving data/Midi/90142231f8ef44e8191b8b12691f724d.mid\n",
      "Saving data/Midi/c74b9b1cf88a4b63add538248c383630.mid\n",
      "Saving data/Midi/4069a9a15897d7b97ca7db91e62f4041.mid\n",
      "Saving data/Midi/ec29853529b6ea88bdfc1a0c5b2d03c4.mid\n",
      "Saving data/Midi/18612486ce2c1a51988748b80f39fb30.mid\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0aab9613539f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_to_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ERROR \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d2fd4bf401c1>\u001b[0m in \u001b[0;36mmidi_to_samples\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_note\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0msingle_note\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mall_notes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnote\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs_time\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msamples_per_measure\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mticks_per_measure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'note_off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_notes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnote\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## LOAD SONGS ##\n",
    "patterns = {}\n",
    "dirs = [\"data/\"]\n",
    "all_samples = []\n",
    "all_lens = []\n",
    "print (\"Loading Songs...\")\n",
    "for dir in dirs:\n",
    "    for root, subdirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            path = root + \"/\" + file\n",
    "            if not (path.endswith('.mid') or path.endswith('.midi')):\n",
    "                continue\n",
    "            try:\n",
    "                samples = midi_to_samples(path)\n",
    "            except Exception as inst:\n",
    "                print (\"ERROR \", path, inst)\n",
    "                continue\n",
    "            if len(samples) < 8:\n",
    "                continue\n",
    "            samples, lens = generate_add_centered_transpose(samples)\n",
    "            all_samples += samples\n",
    "            all_lens += lens\n",
    "            print (\"Saving \" + path)\n",
    "assert(sum(all_lens) == len(all_samples))\n",
    "print (\"Saving \" + str(len(all_samples)) + \" samples...\")\n",
    "all_samples = np.array(all_samples, dtype=np.uint8)\n",
    "all_lens = np.array(all_lens, dtype=np.uint32)\n",
    "np.save('samples.npy', all_samples)\n",
    "np.save('lengths.npy', all_lens)\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_midi(samples, fname, ticks_per_sample, thresh=0.5):\n",
    "    mid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "    ticks_per_measure = 4 * ticks_per_beat\n",
    "    ticks_per_sample = ticks_per_measure / samples_per_measure\n",
    "    abs_time = 0\n",
    "    last_time = 0\n",
    "    for sample in samples:\n",
    "        for y in range(sample.shape[0]):\n",
    "            abs_time += ticks_per_sample\n",
    "            for x in range(sample.shape[1]):\n",
    "                note = x + (128 - num_notes)/2\n",
    "                if sample[y,x] >= thresh and (y == 0 or sample[y-1,x] < thresh):\n",
    "                    delta_time = abs_time - last_time\n",
    "                    track.append(Message('note_on', note=int(note), velocity=127, time=int(delta_time)))\n",
    "                    last_time = abs_time\n",
    "                if sample[y,x] >= thresh and (y == sample.shape[0]-1 or sample[y+1,x] < thresh):\n",
    "                    delta_time = abs_time - last_time\n",
    "                    track.append(Message('note_off', note=int(note), velocity=127, time=int(delta_time)))\n",
    "                    last_time = abs_time\n",
    "    mid.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScores(scores, fname, on_top=True):\n",
    "    plt.clf()\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.plot(scores)\n",
    "    plt.ylim([0.0, 0.009])\n",
    "    plt.xlabel('Epoch')\n",
    "    loc = ('upper right' if on_top else 'lower right')\n",
    "    plt.draw()\n",
    "    plt.savefig(fname)\n",
    "\n",
    "def save_config():\n",
    "    with open('config.txt', 'w') as fout:\n",
    "        fout.write('LR:          ' + str(LR) + '\\n')\n",
    "        fout.write('BN_M:        ' + str(BN_M) + '\\n')\n",
    "        fout.write('BATCH_SIZE:  ' + str(BATCH_SIZE) + '\\n')\n",
    "        fout.write('NUM_OFFSETS: ' + str(NUM_OFFSETS) + '\\n')\n",
    "        fout.write('DO_RATE:     ' + str(DO_RATE) + '\\n')\n",
    "        fout.write('num_songs:   ' + str(num_songs) + '\\n')\n",
    "        fout.write('optimizer:   ' + type(model.optimizer).__name__ + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#  Load Keras\n",
    "###################################\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "#Fix the random seed so that training comparisons are easier to make\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "if WRITE_HISTORY:\n",
    "    #Create folder to save models into\n",
    "    if not os.path.exists('History'):\n",
    "        os.makedirs('History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "(462000, 96, 96)\n",
      "(4414,)\n",
      "Loaded 462000 samples from 4414 songs.\n",
      "462000\n",
      "Padding Songs...\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#  Load Dataset\n",
    "###################################\n",
    "print (\"Loading Data...\")\n",
    "y_samples = np.load('samples.npy')\n",
    "print(y_samples.shape)\n",
    "y_lengths = np.load('lengths.npy')\n",
    "print(y_lengths.shape)\n",
    "num_samples = y_samples.shape[0]\n",
    "num_songs = y_lengths.shape[0]\n",
    "print (\"Loaded \" + str(num_samples) + \" samples from \" + str(num_songs) + \" songs.\")\n",
    "print (np.sum(y_lengths))\n",
    "assert(np.sum(y_lengths) == num_samples)\n",
    "\n",
    "print (\"Padding Songs...\")\n",
    "x_shape = (num_songs * NUM_OFFSETS, 1)\n",
    "y_shape = (num_songs * NUM_OFFSETS, MAX_LENGTH) + y_samples.shape[1:]\n",
    "x_orig = np.expand_dims(np.arange(x_shape[0]), axis=-1)\n",
    "y_orig = np.zeros(y_shape, dtype=y_samples.dtype)\n",
    "cur_ix = 0\n",
    "for i in range(num_songs):\n",
    "    for ofs in range(NUM_OFFSETS):\n",
    "        ix = i*NUM_OFFSETS + ofs\n",
    "        end_ix = cur_ix + y_lengths[i]\n",
    "        for j in range(MAX_LENGTH):\n",
    "            k = (j + ofs) % (end_ix - cur_ix)\n",
    "            y_orig[ix,j] = y_samples[cur_ix + k]\n",
    "    cur_ix = end_ix\n",
    "assert(end_ix == num_samples)\n",
    "x_train = np.copy(x_orig)\n",
    "y_train = np.copy(y_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_song(encoded_output):\n",
    "    return np.squeeze(decoder([np.round(encoded_output), 0])[0])\n",
    "\n",
    "def reg_mean_std(x):\n",
    "    s = K.log(K.sum(x * x))\n",
    "    return s*s\n",
    "\n",
    "def vae_sampling(args):\n",
    "    z_mean, z_log_sigma_sq = args\n",
    "    epsilon = K.random_normal(shape=K.shape(z_mean), mean=0.0, stddev=VAE_B1)\n",
    "    return z_mean + K.exp(z_log_sigma_sq * 0.5) * epsilon\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = VAE_B2 * K.mean(1 + z_log_sigma_sq - K.square(z_mean) - K.exp(z_log_sigma_sq), axis=None)\n",
    "    return xent_loss - kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "test_ix = 0\n",
    "y_test_song = np.copy(y_train[test_ix:test_ix+1])\n",
    "x_test_song = np.copy(x_train[test_ix:test_ix+1])\n",
    "samples_to_midi(y_test_song[0], 'gt.mid', 16)\n",
    "#print(y_train.shape)\n",
    "#print(y_train[test_ix:test_ix+1])\n",
    "print (y_test_song.shape)\n",
    "#print(x_train.shape)\n",
    "\n",
    "#for i in range(num_songs):\n",
    "#    print(i)\n",
    "#    write_song = np.copy(y_train[i:i+1])\n",
    "#    #write_song.sum(axis=0, keepdims=True)\n",
    "#    samples_to_midi(write_song, 'input/gt' + str(i) + '.mid', 16)\n",
    "\n",
    "CONTINUE_TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model...\n",
      "(None, 16, 9216)\n",
      "(None, 3200)\n",
      "(None, 1600)\n",
      "(None, 120)\n",
      "(None, 1600)\n",
      "(None, 3200)\n",
      "(None, 16, 200)\n",
      "(None, 16, 2000)\n",
      "(None, 16, 9216)\n",
      "(None, 16, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#  Create Model\n",
    "###################################\n",
    "if CONTINUE_TRAIN or PLAY_ONLY:\n",
    "    print (\"Loading Model...\")\n",
    "    model = load_model('History/model.h5')\n",
    "else:\n",
    "    print (\"Building Model...\")\n",
    "\n",
    "    if USE_EMBEDDING:\n",
    "        x_in = Input(shape=x_shape[1:])\n",
    "        print (None,) + x_shape[1:]\n",
    "        x = Embedding(x_train.shape[0], PARAM_SIZE, input_length=1)(x_in)\n",
    "        x = Flatten(name='pre_encoder')(x)\n",
    "    else:\n",
    "        x_in = Input(shape=y_shape[1:])\n",
    "#         print (K.int_shape(x_in))\n",
    "#         print (y_shape)\n",
    "#         print ((None,) + y_shape[1:])\n",
    "        x = Reshape((y_shape[1], 9216))(x_in)\n",
    "#         print (K.int_shape(x))\n",
    "        print(np.shape(x))\n",
    "        x = TimeDistributed(Dense(2000, activation='relu'))(x)\n",
    "#         print (K.int_shape(x))\n",
    "\n",
    "        x = TimeDistributed(Dense(200, activation='relu'))(x)\n",
    "#         print (K.int_shape(x))\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        print (K.int_shape(x))\n",
    "\n",
    "        x = Dense(1600, activation='relu')(x)\n",
    "        print (K.int_shape(x))\n",
    "\n",
    "        if USE_VAE:\n",
    "            z_mean = Dense(PARAM_SIZE)(x)\n",
    "            z_log_sigma_sq = Dense(PARAM_SIZE)(x)\n",
    "            x = Lambda(vae_sampling, output_shape=(PARAM_SIZE,), name='pre_encoder')([z_mean, z_log_sigma_sq])\n",
    "        else:\n",
    "            x = Dense(PARAM_SIZE)(x)\n",
    "            x = BatchNormalization(momentum=BN_M, name='pre_encoder')(x)\n",
    "    print (K.int_shape(x))\n",
    "\n",
    "    x = Dense(1600, name='encoder')(x)\n",
    "    x = BatchNormalization(momentum=BN_M)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if DO_RATE > 0:\n",
    "        x = Dropout(DO_RATE)(x)\n",
    "    print (K.int_shape(x))\n",
    "\n",
    "    x = Dense(MAX_LENGTH * 200)(x)\n",
    "    print (K.int_shape(x))\n",
    "    x = Reshape((MAX_LENGTH, 200))(x)\n",
    "    x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if DO_RATE > 0:\n",
    "        x = Dropout(DO_RATE)(x)\n",
    "    print (K.int_shape(x))\n",
    "\n",
    "    x = TimeDistributed(Dense(2000))(x)\n",
    "    x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if DO_RATE > 0:\n",
    "        x = Dropout(DO_RATE)(x)\n",
    "    print (K.int_shape(x))\n",
    "\n",
    "    x = TimeDistributed(Dense(y_shape[2] * y_shape[3], activation='sigmoid'))(x)\n",
    "    print (K.int_shape(x))\n",
    "    x = Reshape((y_shape[1], y_shape[2], y_shape[3]))(x)\n",
    "    print (K.int_shape(x))\n",
    "\n",
    "    if USE_VAE:\n",
    "        model = Model(x_in, x)\n",
    "        model.compile(optimizer=Adam(lr=LR), loss=vae_loss)\n",
    "    else:\n",
    "        model = Model(x_in, x)\n",
    "        model.compile(optimizer=RMSprop(lr=LR), loss='binary_crossentropy')\n",
    "\n",
    "# \tkeras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling SubModels...\n",
      "Training...\n",
      "13/13 [==============================] - 130s 10s/step - loss: 0.0904\n",
      "Train Loss: 0.09039629250764847\n",
      "Saved\n",
      "Means:  [-0.41332796  0.2866957   0.149473    0.10516182 -0.36710292 -0.5700905 ]\n",
      "Evals:  [4.54128574 3.77199952 3.15132464 1.93595627 0.99693107 0.73471586]\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0072\n",
      "Train Loss: 0.007194860372692347\n",
      "13/13 [==============================] - 130s 10s/step - loss: 0.0048\n",
      "Train Loss: 0.004792793653905392\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0040\n",
      "Train Loss: 0.003977346234023571\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0035\n",
      "Train Loss: 0.0035160514526069164\n",
      "13/13 [==============================] - 128s 10s/step - loss: 0.0032\n",
      "Train Loss: 0.003216551383957267\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0031\n",
      "Train Loss: 0.0030795650091022253\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0030\n",
      "Train Loss: 0.003031735308468342\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0030\n",
      "Train Loss: 0.0029791088309139013\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0029\n",
      "Train Loss: 0.0029434324242174625\n",
      "Saved\n",
      "Means:  [-0.08575561 -0.31576735 -0.10574146  0.12109356 -0.3169976   0.23548384]\n",
      "Evals:  [6.30428815 4.39390314 4.32204074 4.08581622 2.59700906 2.14032471]\n",
      "13/13 [==============================] - 133s 10s/step - loss: 0.0029\n",
      "Train Loss: 0.0028958977200090885\n",
      "13/13 [==============================] - 129s 10s/step - loss: 0.0029\n",
      "Train Loss: 0.0028539965860545635\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0028\n",
      "Train Loss: 0.002818106207996607\n",
      "13/13 [==============================] - 133s 10s/step - loss: 0.0028\n",
      "Train Loss: 0.0027924529276788235\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0028\n",
      "Train Loss: 0.002773148939013481\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0028\n",
      "Train Loss: 0.002756570465862751\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0027\n",
      "Train Loss: 0.002726868260651827\n",
      "13/13 [==============================] - 130s 10s/step - loss: 0.0027\n",
      "Train Loss: 0.002714824164286256\n",
      "13/13 [==============================] - 130s 10s/step - loss: 0.0027\n",
      "Train Loss: 0.002679294440895319\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0027\n",
      "Train Loss: 0.002654103562235832\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0026\n",
      "Train Loss: 0.002639324404299259\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0026\n",
      "Train Loss: 0.0026076952926814556\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0026\n",
      "Train Loss: 0.0026004125829786062\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0026\n",
      "Train Loss: 0.0025675175711512566\n",
      "13/13 [==============================] - 126s 10s/step - loss: 0.0025\n",
      "Train Loss: 0.002547729527577758\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0025\n",
      "Train Loss: 0.0025411436799913645\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0025\n",
      "Train Loss: 0.0025104591622948647\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0025\n",
      "Train Loss: 0.0024774884805083275\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0025\n",
      "Train Loss: 0.0024693591985851526\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0024\n",
      "Train Loss: 0.0024452372454106808\n",
      "13/13 [==============================] - 128s 10s/step - loss: 0.0024\n",
      "Train Loss: 0.0024101859889924526\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0024\n",
      "Train Loss: 0.0024014892987906933\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0024\n",
      "Train Loss: 0.0023742085322737694\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0024\n",
      "Train Loss: 0.0023550582118332386\n",
      "13/13 [==============================] - 130s 10s/step - loss: 0.0023\n",
      "Train Loss: 0.0023308685049414635\n",
      "13/13 [==============================] - 132s 10s/step - loss: 0.0023\n",
      "Train Loss: 0.00232787081040442\n",
      "13/13 [==============================] - 127s 10s/step - loss: 0.0023\n",
      "Train Loss: 0.002291761338710785\n",
      "13/13 [==============================] - 130s 10s/step - loss: 0.0023\n",
      "Train Loss: 0.002289638388901949\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0023\n",
      "Train Loss: 0.002270652214065194\n",
      "13/13 [==============================] - 131s 10s/step - loss: 0.0023\n",
      "Train Loss: 0.002250742632895708\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#  Train\n",
    "###################################\n",
    "print (\"Compiling SubModels...\")\n",
    "\n",
    "#deep_inputs = tf.keras.Input(tensor=(inputs))\n",
    "#from tensorflow.python.keras import backend\n",
    "#func = Model([model.get_layer('encoder').input, backend.symbolic_learning_phase()],\n",
    "# [model.layers[-1].output])\n",
    "from tensorflow.python.keras import backend as K\n",
    "func = K.function([model.get_layer('encoder').input, K.symbolic_learning_phase()],\n",
    "              [model.layers[(len(model.layers)-1)].output])\n",
    "enc = Model(inputs=model.input, outputs=model.get_layer('pre_encoder').output)\n",
    "\n",
    "rand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_SONGS, PARAM_SIZE))\n",
    "np.save('rand.npy', rand_vecs)\n",
    "\n",
    "def make_rand_songs(write_dir, rand_vecs):\n",
    "    for i in range(rand_vecs.shape[0]):\n",
    "        x_rand = rand_vecs[i:i+1]\n",
    "        y_song = func([x_rand, False])[0]\n",
    "        samples_to_midi(y_song[0], write_dir + 'rand' + str(i) + '.mid', 16, 0.25)\n",
    "\n",
    "def make_rand_songs_normalized(write_dir, rand_vecs):\n",
    "    if USE_EMBEDDING:\n",
    "        x_enc = np.squeeze(enc.predict(x_orig))\n",
    "    else:\n",
    "        x_enc = np.squeeze(enc.predict(y_orig))\n",
    "\n",
    "    x_mean = np.mean(x_enc, axis=0)\n",
    "    x_stds = np.std(x_enc, axis=0)\n",
    "    x_cov = np.cov((x_enc - x_mean).T)\n",
    "    u, s, v = np.linalg.svd(x_cov)\n",
    "    e = np.sqrt(s)\n",
    "\n",
    "    print (\"Means: \", x_mean[:6])\n",
    "    print (\"Evals: \", e[:6])\n",
    "\n",
    "    np.save(write_dir + 'means.npy', x_mean)\n",
    "    np.save(write_dir + 'stds.npy', x_stds)\n",
    "    np.save(write_dir + 'evals.npy', e)\n",
    "    np.save(write_dir + 'evecs.npy', v)\n",
    "\n",
    "    x_vecs = x_mean + np.dot(rand_vecs * e, v)\n",
    "    make_rand_songs(write_dir, x_vecs)\n",
    "\n",
    "    title = ''\n",
    "    if '/' in write_dir:\n",
    "        title = 'Epoch: ' + write_dir.split('/')[-2][1:]\n",
    "\n",
    "    plt.clf()\n",
    "    e[::-1].sort()\n",
    "    plt.title(title)\n",
    "    plt.bar(np.arange(e.shape[0]), e, align='center')\n",
    "    plt.draw()\n",
    "    plt.savefig(write_dir + 'evals.png')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.title(title)\n",
    "    plt.bar(np.arange(e.shape[0]), x_mean, align='center')\n",
    "    plt.draw()\n",
    "    plt.savefig(write_dir + 'means.png')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.title(title)\n",
    "    plt.bar(np.arange(e.shape[0]), x_stds, align='center')\n",
    "    plt.draw()\n",
    "    plt.savefig(write_dir + 'stds.png')\n",
    "\n",
    "if PLAY_ONLY:\n",
    "    print (\"Generating Songs...\")\n",
    "    make_rand_songs_normalized('', rand_vecs)\n",
    "    for i in range(20):\n",
    "        x_test_song = x_train[i:i+1]\n",
    "        y_song = model.predict(x_test_song, batch_size=BATCH_SIZE)[0]\n",
    "        samples_to_midi(y_song, 'gt' + str(i) + '.mid', 16)\n",
    "    exit(0)\n",
    "\n",
    "print (\"Training...\")\n",
    "save_config()\n",
    "train_loss = []\n",
    "ofs = 0\n",
    "\n",
    "for iter in range(NUM_EPOCHS):\n",
    "    if USE_EMBEDDING:\n",
    "        history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n",
    "    else:\n",
    "        cur_ix = 0\n",
    "        for i in range(num_songs):\n",
    "            end_ix = cur_ix + y_lengths[i]\n",
    "            for j in range(MAX_LENGTH):\n",
    "                k = (j + ofs) % (end_ix - cur_ix)\n",
    "                y_train[i,j] = y_samples[cur_ix + k]\n",
    "            cur_ix = end_ix\n",
    "        assert(end_ix == num_samples)\n",
    "        ofs += 1\n",
    "\n",
    "        history = model.fit(y_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n",
    "\n",
    "    loss = history.history[\"loss\"][-1]\n",
    "    train_loss.append(loss)\n",
    "    print (\"Train Loss: \" + str(train_loss[-1]))\n",
    "\n",
    "# if WRITE_HISTORY:\n",
    "# plotScores(train_loss, 'History/Scores.png', True)\n",
    "# else:\n",
    "    plotScores(train_loss, 'Scores.png', True)\n",
    "\n",
    "    i = iter + 1\n",
    "    if i in [1, 10, 50, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 450] or (i % 100 == 0):\n",
    "        write_dir = ''\n",
    "        if WRITE_HISTORY:\n",
    "            #Create folder to save models into\n",
    "            write_dir = 'History/e' + str(i)\n",
    "            if not os.path.exists(write_dir):\n",
    "                os.makedirs(write_dir)\n",
    "            write_dir += '/'\n",
    "            model.save('History/model.h5')\n",
    "        else:\n",
    "            model.save('model.h5')\n",
    "        print (\"Saved\")\n",
    "\n",
    "        if USE_EMBEDDING:\n",
    "            y_song = model.predict(x_test_song, batch_size=BATCH_SIZE)[0]\n",
    "        else:\n",
    "            y_song = model.predict(y_test_song, batch_size=BATCH_SIZE)[0]\n",
    "        samples_to_pics(write_dir + 'test', y_song)\n",
    "        samples_to_midi(y_song, write_dir + 'test.mid', 16)\n",
    "\n",
    "        make_rand_songs_normalized(write_dir, rand_vecs)\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
