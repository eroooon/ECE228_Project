{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydot==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install graphviz==0.10.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-pydot python-pydot-ng graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theano Version: 1.0.5\n",
      "Keras Version: 2.4.3\n",
      "Tensorflow Version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#import midi\n",
    "import numpy as np\n",
    "import math\n",
    "import sys, random, os\n",
    "from matplotlib import pyplot as plt\n",
    "import pydot\n",
    "import keras\n",
    "import theano\n",
    "\n",
    "\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Reshape, Permute, RepeatVector, ActivityRegularization, TimeDistributed, Lambda, SpatialDropout1D\n",
    "from keras.layers.convolutional import Conv1D, Conv2D, Conv2DTranspose, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.local import LocallyConnected2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "#from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "print (\"Theano Version: \" + theano.__version__)\n",
    "print (\"Keras Version: \" + keras.__version__)\n",
    "print (\"Tensorflow Version: \" + tf.__version__)\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "NUM_EPOCHS = 15\n",
    "LR = 0.001\n",
    "CONTINUE_TRAIN = False\n",
    "PLAY_ONLY = False\n",
    "USE_EMBEDDING = False\n",
    "USE_VAE = False\n",
    "WRITE_HISTORY = True\n",
    "NUM_RAND_SONGS = 10\n",
    "DO_RATE = 0.1\n",
    "BN_M = 0.9\n",
    "VAE_B1 = 0.02\n",
    "VAE_B2 = 0.1\n",
    "\n",
    "BATCH_SIZE = 350\n",
    "MAX_LENGTH = 16\n",
    "PARAM_SIZE = 120\n",
    "NUM_OFFSETS = 16 if USE_EMBEDDING else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility functions ##\n",
    "\n",
    "def transpose_range(samples):\n",
    "\tmerged_sample = np.zeros_like(samples[0])\n",
    "\tfor sample in samples:\n",
    "\t\tmerged_sample = np.maximum(merged_sample, sample)\n",
    "\tmerged_sample = np.amax(merged_sample, axis=0)\n",
    "\tmin_note = np.argmax(merged_sample)\n",
    "\tmax_note = merged_sample.shape[0] - np.argmax(merged_sample[::-1])\n",
    "\treturn min_note, max_note\n",
    "\n",
    "def generate_add_centered_transpose(samples):\n",
    "\tnum_notes = samples[0].shape[1]\n",
    "\tmin_note, max_note = transpose_range(samples)\n",
    "\ts = num_notes/2 - (max_note + min_note)/2\n",
    "\tout_samples = samples\n",
    "\tout_lens = [len(samples), len(samples)]\n",
    "\tfor i in range(len(samples)):\n",
    "\t\tout_sample = np.zeros_like(samples[i])\n",
    "\t\tout_sample[:,int(min_note+s):int(max_note+s)] = samples[i][:,min_note:max_note]\n",
    "\t\tout_samples.append(out_sample)\n",
    "\treturn out_samples, out_lens\n",
    "\t\n",
    "def generate_all_transpose(samples, radius=6):\n",
    "\tnum_notes = samples[0].shape[1]\n",
    "\tmin_note, max_note = transpose_range(samples)\n",
    "\tmin_shift = -min(radius, min_note)\n",
    "\tmax_shift = min(radius, num_notes - max_note)\n",
    "\tout_samples = []\n",
    "\tout_lens = []\n",
    "\tfor s in range(min_shift, max_shift):\n",
    "\t\tfor i in range(len(samples)):\n",
    "\t\t\tout_sample = np.zeros_like(samples[i])\n",
    "\t\t\tout_sample[:,min_note+s:max_note+s] = samples[i][:,min_note:max_note]\n",
    "\t\t\tout_samples.append(out_sample)\n",
    "\t\tout_lens.append(len(samples))\n",
    "\treturn out_samples, out_lens\n",
    "\n",
    "def sample_to_pic(fname, sample, thresh=None):\n",
    "\tif thresh is not None:\n",
    "\t\tinverted = np.where(sample > thresh, 0, 1)\n",
    "\telse:\n",
    "\t\tinverted = 1.0 - sample\n",
    "\tcv2.imwrite(fname, inverted * 255)\n",
    "\n",
    "def samples_to_pics(dir, samples, thresh=None):\n",
    "\tif not os.path.exists(dir): os.makedirs(dir)\n",
    "\tfor i in range(samples.shape[0]):\n",
    "\t\tsample_to_pic(dir + '/s' + str(i) + '.png', samples[i], thresh)\n",
    "\n",
    "def pad_songs(y, y_lens, max_len):\n",
    "\ty_shape = (y_lens.shape[0], max_len) + y.shape[1:]\n",
    "\ty_train = np.zeros(y_shape, dtype=np.float32)\n",
    "\tcur_ix = 0\n",
    "\tfor i in range(y_lens.shape[0]):\n",
    "\t\tend_ix = cur_ix + y_lens[i]\n",
    "\t\tfor j in range(max_len):\n",
    "\t\t\tk = j % (end_ix - cur_ix)\n",
    "\t\t\ty_train[i,j] = y[cur_ix + k]\n",
    "\t\tcur_ix = end_ix\n",
    "\tassert(end_ix == y.shape[0])\n",
    "\treturn y_train\n",
    "\n",
    "def sample_to_pattern(sample, ix, size):\n",
    "\tnum_pats = 0\n",
    "\tpat_types = {}\n",
    "\tpat_list = []\n",
    "\tnum_samples = len(sample) if type(sample) is list else sample.shape[0]\n",
    "\tfor i in range(size):\n",
    "\t\tj = (ix + i) % num_samples\n",
    "\t\tmeasure = sample[j].tobytes()\n",
    "\t\tif measure not in pat_types:\n",
    "\t\t\tpat_types[measure] = num_pats\n",
    "\t\t\tnum_pats += 1\n",
    "\t\tpat_list.append(pat_types[measure])\n",
    "\treturn str(pat_list), pat_types\n",
    "\n",
    "def embed_samples(samples):\n",
    "\tnote_dict = {}\n",
    "\tn, m, p = samples.shape\n",
    "\tsamples.flags.writeable = False\n",
    "\te_samples = np.empty(samples.shape[:2], dtype=np.int32)\n",
    "\tfor i in range(n):\n",
    "\t\tfor j in range(m):\n",
    "\t\t\tnote = samples[i,j].data\n",
    "\t\t\tif note not in note_dict:\n",
    "\t\t\t\tnote_dict[note] = len(note_dict)\n",
    "\t\t\te_samples[i,j] = note_dict[note]\n",
    "\tsamples.flags.writeable = True\n",
    "\tlookup = np.empty((len(note_dict), p), dtype=np.float32)\n",
    "\tfor k in note_dict:\n",
    "\t\tlookup[note_dict[k]] = k\n",
    "\treturn e_samples, note_dict, lookup\n",
    "\n",
    "def e_to_samples(e_samples, lookup):\n",
    "\tsamples = np.empty(e_samples.shape + lookup.shape[-1:], dtype=np.float32)\n",
    "\tn, m = e_samples.shape\n",
    "\tfor i in range(n):\n",
    "\t\tfor j in range(m):\n",
    "\t\t\tsamples[i,j] = lookup[e_samples[i,j]]\n",
    "\treturn samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_notes = 96\n",
    "samples_per_measure = 96\n",
    "\n",
    "def midi_to_samples(fname):\n",
    "    has_time_sig = False\n",
    "    flag_warning = False\n",
    "    mid = MidiFile(fname)\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "    ticks_per_measure = 4 * ticks_per_beat\n",
    "\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        for msg in track:\n",
    "            if msg.type == 'time_signature':\n",
    "                new_tpm = msg.numerator * ticks_per_beat * 4 / msg.denominator\n",
    "                if has_time_sig and new_tpm != ticks_per_measure:\n",
    "                    flag_warning = True\n",
    "                ticks_per_measure = new_tpm\n",
    "                has_time_sig = True\n",
    "    if flag_warning:\n",
    "#         print (\"  ^^^^^^ WARNING ^^^^^^ \" )\n",
    "        return []\n",
    "    all_notes = {}\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        abs_time = 0\n",
    "        for msg in track:\n",
    "            abs_time += msg.time\n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity == 0:\n",
    "                    continue\n",
    "                note = msg.note - (128 - num_notes)/2\n",
    "                assert(note >= 0 and note < num_notes)\n",
    "                if note not in all_notes:\n",
    "                    all_notes[note] = []\n",
    "                else:\n",
    "                    single_note = all_notes[note][-1]\n",
    "                    if len(single_note) == 1:\n",
    "                        single_note.append(single_note[0] + 1)\n",
    "                all_notes[note].append([abs_time * samples_per_measure / ticks_per_measure])\n",
    "            elif msg.type == 'note_off':\n",
    "                if len(all_notes[note][-1]) != 1:\n",
    "                    continue\n",
    "                all_notes[note][-1].append(abs_time * samples_per_measure / ticks_per_measure)    \n",
    "    for note in all_notes:\n",
    "        for start_end in all_notes[note]:\n",
    "            if len(start_end) == 1:\n",
    "                start_end.append(start_end[0] + 1)\n",
    "    samples = []\n",
    "    for note in all_notes:\n",
    "        for start, end in all_notes[note]:\n",
    "            sample_ix = start / samples_per_measure\n",
    "            while len(samples) <= sample_ix:\n",
    "                samples.append(np.zeros((samples_per_measure, num_notes), dtype=np.uint8))\n",
    "            sample = samples[int(sample_ix)]\n",
    "            start_ix = start - sample_ix * samples_per_measure        \n",
    "            if False:\n",
    "                end_ix = min(end - sample_ix * samples_per_measure, samples_per_measure)\n",
    "                while start_ix < end_ix:\n",
    "                    sample[int(start_ix), int(note)] = 1\n",
    "                    start_ix += 1\n",
    "            else:\n",
    "                sample[int(start_ix), int(note)] = 1 \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Songs...\n",
      "Saving data/Midi/2d234b4eab541079d8510d9b782857be.mid\n",
      "Saving data/Midi/71d5b55cea40593fc9f955eab2c33d19.mid\n",
      "Saving data/Midi/9b6b8381cd5e3a80530d28fb6addfcee.mid\n",
      "Saving data/Midi/7175b1100bf84c4b54fabcace4e34346.mid\n",
      "Saving data/Midi/e940cbe0fd7626f7600f1ffa6eae6c58.mid\n",
      "ERROR  data/Midi/1c06b0b2cd06544d9964c18e97ce3e97.mid \n",
      "Saving data/Midi/82cd7d2de03818bc228b0d1933ef9628.mid\n",
      "Saving data/Midi/34f0ca56001e21cf12b5f525e516f7c1.mid\n",
      "Saving data/Midi/5117c65cae61fc3dce3b3bb8020172fe.mid\n",
      "ERROR  data/Midi/b4e649dac1f22d10298d36c76f3a1f7f.mid \n",
      "Saving data/Midi/e1f9ac9d54226c36fcbf60d55448eacd.mid\n",
      "Saving data/Midi/37d1091c4d91fbf4c96a921bd2f1eef0.mid\n",
      "Saving data/Midi/07b1ee29aa0ad0ca74c15c57f15e4d87.mid\n",
      "Saving data/Midi/db3e9dc1cfe4bd92a83fccba6e71ce7c.mid\n",
      "Saving data/Midi/ae03f180ed250536aa97a86d3add84fa.mid\n",
      "Saving data/Midi/9024e5a8fa5e78aac10c1a6e3970f805.mid\n",
      "Saving data/Midi/7b1bcea95b452d778efd79231b3b9c72.mid\n",
      "Saving data/Midi/29f38d8e83c3e860d20f2d5c26cf6349.mid\n",
      "Saving data/Midi/594990787f4f8a3ddef906cacc2caff2.mid\n",
      "Saving data/Midi/0bc0ef6c1e6850f458f302325baf46fc.mid\n",
      "Saving data/Midi/094b969daa599ba98bcf00beb8048bcb.mid\n",
      "Saving data/Midi/0d1be740159082ac0e75c40c2ed73cf1.mid\n",
      "Saving data/Midi/79e0f4b092cba2ec0cd436136ad24e85.mid\n",
      "Saving data/Midi/7c5f48cb060c2bd4496047e11400d717.mid\n",
      "Saving data/Midi/68a61ef04c6cd76cd83e68e036ee3771.mid\n",
      "Saving data/Midi/f43ac1cf557090ca62dfa74e76cd7e66.mid\n",
      "Saving data/Midi/7a950bc8bb1f7129eeda359bec79d5e0.mid\n",
      "Saving data/Midi/b950461b0d8e519de196b9fbbdf8e7d6.mid\n",
      "Saving data/Midi/aeb74f88797df6a32b9977778548c0ee.mid\n",
      "Saving data/Midi/5d307c3b71ee60056d919324aeab69cc.mid\n",
      "Saving data/Midi/3673b26f4d18e93d9b09119e06603a42.mid\n",
      "Saving data/Midi/8346c967420df257c0f672afeeff9907.mid\n",
      "Saving data/Midi/5beaa36682e60db109527f87af6123dd.mid\n",
      "Saving data/Midi/52b309591d52e940eb534dd635a317d0.mid\n",
      "Saving data/Midi/2ae374d4e04064a256b1ec485cd09789.mid\n",
      "Saving data/Midi/7f9de2634e121b7f6e7d569522be0fe5.mid\n",
      "Saving data/Midi/69193d1c3e5df54174f95ca7032bba6f.mid\n",
      "Saving data/Midi/27f90f699dae2c490c2ec779bf1efe17.mid\n",
      "Saving data/Midi/f8138c345245e573260fa5c1cfb3e12f.mid\n",
      "Saving data/Midi/14bdef979c3d2e9816dff833d9a4be29.mid\n",
      "Saving data/Midi/d3791a612f4f38918608c110ef4ba0d0.mid\n",
      "Saving data/Midi/95eb7814610622827015920dd70104e8.mid\n",
      "Saving data/Midi/41f2a4b6dbc3bd5486302a81422ddeed.mid\n",
      "Saving data/Midi/da402f26c466ad6e9f4f1b877a2d322e.mid\n",
      "Saving data/Midi/19f8a01cbc0fb2466f3e3ee1faa62518.mid\n",
      "Saving data/Midi/f4534723697342641d99d934c6b6f406.mid\n",
      "Saving data/Midi/7a63bd687a81798a5b198f6df577686a.mid\n",
      "Saving data/Midi/fc41fc6b99548930bbc22070d96042d4.mid\n",
      "Saving data/Midi/950c75286e49cad75d8c6a5d74a5bdef.mid\n",
      "Saving data/Midi/656483758812707b4c8b7fe84c109aad.mid\n",
      "ERROR  data/Midi/ab74dda2c12c2d9cd5b1e070f41b7852.mid \n",
      "Saving data/Midi/a2883b6a8a85f7d2e82f614e9878acc2.mid\n",
      "Saving data/Midi/83777120274dbee46baaf6efceaf9ce3.mid\n",
      "Saving data/Midi/03de0ec82c000a7a6a4e0f08b5c47baa.mid\n",
      "Saving data/Midi/1ca6d88d918bcea57d950e4b10a5eb74.mid\n",
      "Saving data/Midi/6e085eb45d0478d2fe581079ef6140a3.mid\n",
      "Saving data/Midi/7050706e2bf7f96c3c9b7526000a785d.mid\n",
      "Saving data/Midi/09d3ebe900c43f2281a9cc10869b56a7.mid\n",
      "Saving data/Midi/102bb99ef51ff099abecbcb0695aaae5.mid\n",
      "Saving data/Midi/e2efe8187edd18c366830190fa0dd778.mid\n",
      "Saving data/Midi/1278dae0064a97c8f7469a78a377e419.mid\n",
      "Saving data/Midi/2840ee87c9e4eadf64680d55ab664c54.mid\n",
      "Saving data/Midi/29f1e597771e9acdc1661ec1a191594c.mid\n",
      "ERROR  data/Midi/38c553ffa49be0aeaea65c2d34869485.mid \n",
      "Saving data/Midi/61b265edaadb074189799640e8ede907.mid\n",
      "Saving data/Midi/19df6be1c870f8371ec3866dd5ba3d5b.mid\n",
      "Saving data/Midi/b23e0a3466a90967d2b162bd1be1ef5f.mid\n",
      "Saving data/Midi/96b8af6a2d8f9ebcb9ee97a7d4074f31.mid\n",
      "Saving data/Midi/fe4b69b6861ce010bb7f3e5e42112d00.mid\n",
      "Saving data/Midi/01feaae09114a179013d04061fdc5d3d.mid\n",
      "Saving data/Midi/9b8cede3236a380b3d4526b07310d337.mid\n",
      "Saving data/Midi/2b51bd928f5adea9e197480bc866946b.mid\n",
      "Saving data/Midi/a81bbc2dffab53960d13dd623c574700.mid\n",
      "Saving data/Midi/efe3efa99094003b66bb5fadf5e9d2cb.mid\n",
      "Saving data/Midi/0ec66aa2db6419c69ca47347b9c702fa.mid\n",
      "Saving data/Midi/9c85783caf2d12613623e8fe051affab.mid\n",
      "Saving data/Midi/5fdec372b630ce6fe62e9081c8a6d43e.mid\n",
      "Saving data/Midi/9d6b939dd0eae2ffdde8dd83fd12eecb.mid\n",
      "Saving data/Midi/f02c2e06fd359d17e1001b37617feee8.mid\n",
      "Saving data/Midi/fd8a74721e12693847404a08f750d345.mid\n",
      "Saving data/Midi/64d796f52f01d119100bc7414cc16312.mid\n",
      "Saving data/Midi/fb29546ab64f1bcae270ad3063c5f081.mid\n",
      "Saving data/Midi/658a98b26fd00b26a16db71186f46ea6.mid\n",
      "Saving data/Midi/b47325380c53eb11b8d9c166139aa159.mid\n",
      "Saving data/Midi/4483f8f404d7ec3b7b7b6b779222e5f4.mid\n",
      "Saving data/Midi/8577f1f8be90b38a83645f1743a2fb2d.mid\n",
      "Saving data/Midi/e24368327ff0677878fd3555de6116c2.mid\n",
      "Saving data/Midi/20e37426a709c37939df1a117a038da1.mid\n",
      "Saving data/Midi/29ea13be7dfe7e3361cedce59dd93c7a.mid\n",
      "Saving data/Midi/d00c09fccf7d0d905f04b072d48e27da.mid\n",
      "Saving data/Midi/c054012d20ee41c86c22227cdb801ef5.mid\n",
      "Saving data/Midi/3ecd0d157746923a68c45e9aa0f8d2fd.mid\n",
      "ERROR  data/Midi/eb81377917c867c99e665f66be847871.mid \n",
      "Saving data/Midi/f57a3b48fe9917616f1c81802b5db382.mid\n",
      "Saving data/Midi/e1ee6f9ee94ae198831522d034d386f7.mid\n",
      "Saving data/Midi/f126a0f84ad309d7c2efdaa3103b19fb.mid\n",
      "Saving data/Midi/9470913c163995333e9dafd111a22a2c.mid\n",
      "Saving data/Midi/5ef7440569ede27694124e3b3cefd169.mid\n",
      "Saving data/Midi/2e08b60d5e1f15c81266f44762e0d8f0.mid\n",
      "Saving data/Midi/b0cb81182ebd2ab01ac084631d24bd97.mid\n",
      "Saving data/Midi/b65151a2961974eb991f6b124ba93243.mid\n",
      "Saving data/Midi/4c67ef2d56bf8fa4614ff30fd6473eb0.mid\n",
      "ERROR  data/Midi/f08b1559ab5045730fac33c3122e9e9d.mid \n",
      "Saving data/Midi/085f3488516abd3ccf47c54048e28ee9.mid\n",
      "Saving data/Midi/a382882eabd10916f95910b3ac67d97f.mid\n",
      "ERROR  data/Midi/92aa62f89a1d295852d4b7d459075481.mid \n",
      "ERROR  data/Midi/341459fca6a7f89897d64af9db48e88e.mid \n",
      "Saving data/Midi/b285f3e674176d7ae5c824a72a421a6d.mid\n",
      "Saving data/Midi/027eee60e875d9543de1ccffec52730c.mid\n",
      "ERROR  data/Midi/95194d2b93d19299f77319c15bf1c37c.mid \n",
      "Saving data/Midi/7ccd8db7ea1ba5e408c406d1a4c8744e.mid\n",
      "ERROR  data/Midi/3e0ff0b3b35c8976de156df36a573c48.mid \n",
      "Saving data/Midi/310dde8fa3ce89266756614516ea354d.mid\n",
      "Saving data/Midi/c0899e0ba0fc34b841734ace9c2cb032.mid\n",
      "Saving data/Midi/5fd2a8329b56ff29106a1e6b181ea5e2.mid\n",
      "Saving data/Midi/56b5f9be540abd40dd66769ae4d064bf.mid\n",
      "Saving data/Midi/ad97b6a46ec8978a734b0a2566393105.mid\n",
      "Saving data/Midi/8b675d7164abac0611defb1914c46b38.mid\n",
      "Saving data/Midi/122f7e85c871910c1605908257dc76f2.mid\n",
      "ERROR  data/Midi/64ad222622f982a4cabdf1e15c366d5a.mid \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0aab9613539f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_to_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ERROR \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d2fd4bf401c1>\u001b[0m in \u001b[0;36mmidi_to_samples\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhas_time_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mflag_warning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMidiFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mticks_per_beat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticks_per_beat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mticks_per_measure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mticks_per_beat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, file, type, ticks_per_beat, charset, debug, clip, tracks)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_track\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 self.tracks.append(read_track(infile,\n\u001b[1;32m    360\u001b[0m                                               \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                                               clip=self.clip))\n\u001b[0m\u001b[1;32m    362\u001b[0m                 \u001b[0;31m# TODO: used to ignore EOFError. I hope things still work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36mread_track\u001b[0;34m(infile, debug, clip)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sysex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_byte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeek_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36mread_message\u001b[0;34m(infile, status_byte, peek_data, delta, clip)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data byte must be in range 0..127'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstatus_byte\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/messages/messages.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(cl, data, time)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[1;32m    149\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mmsgdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsgdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mmsgdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSysexData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsgdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/messages/decode.py\u001b[0m in \u001b[0;36mdecode_message\u001b[0;34m(msg_bytes, time, check)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mcheck_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus_byte\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_SPECIAL_CASES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/messages/checks.py\u001b[0m in \u001b[0;36mcheck_data\u001b[0;34m(data_bytes)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbyte\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconvert_py2_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcheck_data_byte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mido/messages/checks.py\u001b[0m in \u001b[0;36mcheck_data_byte\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_data_byte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data byte must be int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m127\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## LOAD SONGS ##\n",
    "patterns = {}\n",
    "dirs = [\"data/\"]\n",
    "all_samples = []\n",
    "all_lens = []\n",
    "print (\"Loading Songs...\")\n",
    "for dir in dirs:\n",
    "    for root, subdirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            path = root + \"/\" + file\n",
    "            if not (path.endswith('.mid') or path.endswith('.midi')):\n",
    "                continue\n",
    "            try:\n",
    "                samples = midi_to_samples(path)\n",
    "            except Exception as inst:\n",
    "                print (\"ERROR \", path, inst)\n",
    "                continue\n",
    "            if len(samples) < 8:\n",
    "                continue\n",
    "            samples, lens = generate_add_centered_transpose(samples)\n",
    "            all_samples += samples\n",
    "            all_lens += lens\n",
    "            print (\"Saving \" + path)\n",
    "assert(sum(all_lens) == len(all_samples))\n",
    "print (\"Saving \" + str(len(all_samples)) + \" samples...\")\n",
    "all_samples = np.array(all_samples, dtype=np.uint8)\n",
    "all_lens = np.array(all_lens, dtype=np.uint32)\n",
    "np.save('samples.npy', all_samples)\n",
    "np.save('lengths.npy', all_lens)\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_midi(samples, fname, ticks_per_sample, thresh=0.5):\n",
    "    mid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "    ticks_per_measure = 4 * ticks_per_beat\n",
    "    ticks_per_sample = ticks_per_measure / samples_per_measure\n",
    "    abs_time = 0\n",
    "    last_time = 0\n",
    "    for sample in samples:\n",
    "        for y in range(sample.shape[0]):\n",
    "            abs_time += ticks_per_sample\n",
    "            for x in range(sample.shape[1]):\n",
    "                note = x + (128 - num_notes)/2\n",
    "                if sample[y,x] >= thresh and (y == 0 or sample[y-1,x] < thresh):\n",
    "                    delta_time = abs_time - last_time\n",
    "                    track.append(Message('note_on', note=int(note), velocity=127, time=int(delta_time)))\n",
    "                    last_time = abs_time\n",
    "                if sample[y,x] >= thresh and (y == sample.shape[0]-1 or sample[y+1,x] < thresh):\n",
    "                    delta_time = abs_time - last_time\n",
    "                    track.append(Message('note_off', note=int(note), velocity=127, time=int(delta_time)))\n",
    "                    last_time = abs_time\n",
    "    mid.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Loaded 462000 samples from 4414 songs.\n",
      "462000\n",
      "Padding Songs...\n",
      "(1, 16, 96, 96)\n",
      "Building Model...\n",
      "(None, 16, 96, 96)\n",
      "(4414, 16, 96, 96)\n",
      "(None, 16, 96, 96)\n",
      "(None, 16, 9216)\n",
      "(None, 16, 2000)\n",
      "(None, 16, 200)\n",
      "(None, 3200)\n",
      "(None, 1600)\n",
      "(None, 120)\n",
      "(None, 1600)\n",
      "(None, 3200)\n",
      "(None, 16, 200)\n",
      "(None, 16, 2000)\n",
      "(None, 16, 9216)\n",
      "(None, 16, 96, 96)\n",
      "Compiling SubModels...\n",
      "Training...\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7166"
     ]
    }
   ],
   "source": [
    "def plotScores(scores, fname, on_top=True):\n",
    "\tplt.clf()\n",
    "\tax = plt.gca()\n",
    "\tax.yaxis.tick_right()\n",
    "\tax.yaxis.set_ticks_position('both')\n",
    "\tax.yaxis.grid(True)\n",
    "\tplt.plot(scores)\n",
    "\tplt.ylim([0.0, 0.009])\n",
    "\tplt.xlabel('Epoch')\n",
    "\tloc = ('upper right' if on_top else 'lower right')\n",
    "\tplt.draw()\n",
    "\tplt.savefig(fname)\n",
    "\n",
    "def save_config():\n",
    "\twith open('config.txt', 'w') as fout:\n",
    "\t\tfout.write('LR:          ' + str(LR) + '\\n')\n",
    "\t\tfout.write('BN_M:        ' + str(BN_M) + '\\n')\n",
    "\t\tfout.write('BATCH_SIZE:  ' + str(BATCH_SIZE) + '\\n')\n",
    "\t\tfout.write('NUM_OFFSETS: ' + str(NUM_OFFSETS) + '\\n')\n",
    "\t\tfout.write('DO_RATE:     ' + str(DO_RATE) + '\\n')\n",
    "\t\tfout.write('num_songs:   ' + str(num_songs) + '\\n')\n",
    "\t\tfout.write('optimizer:   ' + type(model.optimizer).__name__ + '\\n')\n",
    "\n",
    "###################################\n",
    "#  Load Keras\n",
    "###################################\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "#Fix the random seed so that training comparisons are easier to make\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "if WRITE_HISTORY:\n",
    "\t#Create folder to save models into\n",
    "\tif not os.path.exists('History'):\n",
    "\t\tos.makedirs('History')\n",
    "\n",
    "###################################\n",
    "#  Load Dataset\n",
    "###################################\n",
    "print (\"Loading Data...\")\n",
    "y_samples = np.load('samples.npy')\n",
    "y_lengths = np.load('lengths.npy')\n",
    "num_samples = y_samples.shape[0]\n",
    "num_songs = y_lengths.shape[0]\n",
    "print (\"Loaded \" + str(num_samples) + \" samples from \" + str(num_songs) + \" songs.\")\n",
    "print (np.sum(y_lengths))\n",
    "assert(np.sum(y_lengths) == num_samples)\n",
    "\n",
    "print (\"Padding Songs...\")\n",
    "x_shape = (num_songs * NUM_OFFSETS, 1)\n",
    "y_shape = (num_songs * NUM_OFFSETS, MAX_LENGTH) + y_samples.shape[1:]\n",
    "x_orig = np.expand_dims(np.arange(x_shape[0]), axis=-1)\n",
    "y_orig = np.zeros(y_shape, dtype=y_samples.dtype)\n",
    "cur_ix = 0\n",
    "for i in range(num_songs):\n",
    "\tfor ofs in range(NUM_OFFSETS):\n",
    "\t\tix = i*NUM_OFFSETS + ofs\n",
    "\t\tend_ix = cur_ix + y_lengths[i]\n",
    "\t\tfor j in range(MAX_LENGTH):\n",
    "\t\t\tk = (j + ofs) % (end_ix - cur_ix)\n",
    "\t\t\ty_orig[ix,j] = y_samples[cur_ix + k]\n",
    "\tcur_ix = end_ix\n",
    "assert(end_ix == num_samples)\n",
    "x_train = np.copy(x_orig)\n",
    "y_train = np.copy(y_orig)\n",
    "\n",
    "def to_song(encoded_output):\n",
    "\treturn np.squeeze(decoder([np.round(encoded_output), 0])[0])\n",
    "\n",
    "def reg_mean_std(x):\n",
    "\ts = K.log(K.sum(x * x))\n",
    "\treturn s*s\n",
    "\n",
    "def vae_sampling(args):\n",
    "\tz_mean, z_log_sigma_sq = args\n",
    "\tepsilon = K.random_normal(shape=K.shape(z_mean), mean=0.0, stddev=VAE_B1)\n",
    "\treturn z_mean + K.exp(z_log_sigma_sq * 0.5) * epsilon\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "\txent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "\tkl_loss = VAE_B2 * K.mean(1 + z_log_sigma_sq - K.square(z_mean) - K.exp(z_log_sigma_sq), axis=None)\n",
    "\treturn xent_loss - kl_loss\n",
    "\t\n",
    "test_ix = 0\n",
    "y_test_song = np.copy(y_train[test_ix:test_ix+1])\n",
    "x_test_song = np.copy(x_train[test_ix:test_ix+1])\n",
    "samples_to_midi(y_test_song[0], 'gt.mid', 16)\n",
    "print (y_test_song.shape)\n",
    "\n",
    "CONTINUE_TRAIN = False\n",
    "###################################\n",
    "#  Create Model\n",
    "###################################\n",
    "if CONTINUE_TRAIN or PLAY_ONLY:\n",
    "\tprint (\"Loading Model...\")\n",
    "\tmodel = load_model('History/model.h5')\n",
    "else:\n",
    "\tprint (\"Building Model...\")\n",
    "\n",
    "\tif USE_EMBEDDING:\n",
    "\t\tx_in = Input(shape=x_shape[1:])\n",
    "\t\tprint (None,) + x_shape[1:]\n",
    "\t\tx = Embedding(x_train.shape[0], PARAM_SIZE, input_length=1)(x_in)\n",
    "\t\tx = Flatten(name='pre_encoder')(x)\n",
    "\telse:\n",
    "\t\tx_in = Input(shape=y_shape[1:])\n",
    "\t\tprint (K.int_shape(x_in))\n",
    "\t\tprint (y_shape)\n",
    "\t\tprint ((None,) + y_shape[1:])\n",
    "\t\tx = Reshape((y_shape[1], 9216))(x_in)\n",
    "\t\tprint (K.int_shape(x))\n",
    "\t\t\n",
    "\t\tx = TimeDistributed(Dense(2000, activation='relu'))(x)\n",
    "\t\tprint (K.int_shape(x))\n",
    "\t\t\n",
    "\t\tx = TimeDistributed(Dense(200, activation='relu'))(x)\n",
    "\t\tprint (K.int_shape(x))\n",
    "\n",
    "\t\tx = Flatten()(x)\n",
    "\t\tprint (K.int_shape(x))\n",
    "\n",
    "\t\tx = Dense(1600, activation='relu')(x)\n",
    "\t\tprint (K.int_shape(x))\n",
    "\t\t\n",
    "\t\tif USE_VAE:\n",
    "\t\t\tz_mean = Dense(PARAM_SIZE)(x)\n",
    "\t\t\tz_log_sigma_sq = Dense(PARAM_SIZE)(x)\n",
    "\t\t\tx = Lambda(vae_sampling, output_shape=(PARAM_SIZE,), name='pre_encoder')([z_mean, z_log_sigma_sq])\n",
    "\t\telse:\n",
    "\t\t\tx = Dense(PARAM_SIZE)(x)\n",
    "\t\t\tx = BatchNormalization(momentum=BN_M, name='pre_encoder')(x)\n",
    "\tprint (K.int_shape(x))\n",
    "\t\n",
    "\tx = Dense(1600, name='encoder')(x)\n",
    "\tx = BatchNormalization(momentum=BN_M)(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tif DO_RATE > 0:\n",
    "\t\tx = Dropout(DO_RATE)(x)\n",
    "\tprint (K.int_shape(x))\n",
    "\n",
    "\tx = Dense(MAX_LENGTH * 200)(x)\n",
    "\tprint (K.int_shape(x))\n",
    "\tx = Reshape((MAX_LENGTH, 200))(x)\n",
    "\tx = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tif DO_RATE > 0:\n",
    "\t\tx = Dropout(DO_RATE)(x)\n",
    "\tprint (K.int_shape(x))\n",
    "\n",
    "\tx = TimeDistributed(Dense(2000))(x)\n",
    "\tx = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tif DO_RATE > 0:\n",
    "\t\tx = Dropout(DO_RATE)(x)\n",
    "\tprint (K.int_shape(x))\n",
    "\n",
    "\tx = TimeDistributed(Dense(y_shape[2] * y_shape[3], activation='sigmoid'))(x)\n",
    "\tprint (K.int_shape(x))\n",
    "\tx = Reshape((y_shape[1], y_shape[2], y_shape[3]))(x)\n",
    "\tprint (K.int_shape(x))\n",
    "\t\n",
    "\tif USE_VAE:\n",
    "\t\tmodel = Model(x_in, x)\n",
    "\t\tmodel.compile(optimizer=Adam(lr=LR), loss=vae_loss)\n",
    "\telse:\n",
    "\t\tmodel = Model(x_in, x)\n",
    "\t\tmodel.compile(optimizer=RMSprop(lr=LR), loss='binary_crossentropy')\n",
    "\n",
    "# \tkeras.utils.plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "###################################\n",
    "#  Train\n",
    "###################################\n",
    "print (\"Compiling SubModels...\")\n",
    "\n",
    "#deep_inputs = tf.keras.Input(tensor=(inputs))\n",
    "#from tensorflow.python.keras import backend\n",
    "#func = Model([model.get_layer('encoder').input, backend.symbolic_learning_phase()],\n",
    "#\t\t\t\t  [model.layers[-1].output])\n",
    "from tensorflow.python.keras import backend as K\n",
    "func = K.function([model.get_layer('encoder').input, K.symbolic_learning_phase()],\n",
    "\t\t\t\t  [model.layers[(len(model.layers)-1)].output])\n",
    "enc = Model(inputs=model.input, outputs=model.get_layer('pre_encoder').output)\n",
    "\n",
    "rand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_SONGS, PARAM_SIZE))\n",
    "np.save('rand.npy', rand_vecs)\n",
    "\n",
    "def make_rand_songs(write_dir, rand_vecs):\n",
    "\tfor i in range(rand_vecs.shape[0]):\n",
    "\t\tx_rand = rand_vecs[i:i+1]\n",
    "\t\ty_song = func([x_rand, False])[0]\n",
    "\t\tsamples_to_midi(y_song[0], write_dir + 'rand' + str(i) + '.mid', 16, 0.25)\n",
    "\n",
    "def make_rand_songs_normalized(write_dir, rand_vecs):\n",
    "\tif USE_EMBEDDING:\n",
    "\t\tx_enc = np.squeeze(enc.predict(x_orig))\n",
    "\telse:\n",
    "\t\tx_enc = np.squeeze(enc.predict(y_orig))\n",
    "\t\n",
    "\tx_mean = np.mean(x_enc, axis=0)\n",
    "\tx_stds = np.std(x_enc, axis=0)\n",
    "\tx_cov = np.cov((x_enc - x_mean).T)\n",
    "\tu, s, v = np.linalg.svd(x_cov)\n",
    "\te = np.sqrt(s)\n",
    "\n",
    "\tprint (\"Means: \", x_mean[:6])\n",
    "\tprint (\"Evals: \", e[:6])\n",
    "\t\n",
    "\tnp.save(write_dir + 'means.npy', x_mean)\n",
    "\tnp.save(write_dir + 'stds.npy', x_stds)\n",
    "\tnp.save(write_dir + 'evals.npy', e)\n",
    "\tnp.save(write_dir + 'evecs.npy', v)\n",
    "\n",
    "\tx_vecs = x_mean + np.dot(rand_vecs * e, v)\n",
    "\tmake_rand_songs(write_dir, x_vecs)\n",
    "\t\n",
    "\ttitle = ''\n",
    "\tif '/' in write_dir:\n",
    "\t\ttitle = 'Epoch: ' + write_dir.split('/')[-2][1:]\n",
    "\t\n",
    "\tplt.clf()\n",
    "\te[::-1].sort()\n",
    "\tplt.title(title)\n",
    "\tplt.bar(np.arange(e.shape[0]), e, align='center')\n",
    "\tplt.draw()\n",
    "\tplt.savefig(write_dir + 'evals.png')\n",
    "\n",
    "\tplt.clf()\n",
    "\tplt.title(title)\n",
    "\tplt.bar(np.arange(e.shape[0]), x_mean, align='center')\n",
    "\tplt.draw()\n",
    "\tplt.savefig(write_dir + 'means.png')\n",
    "\t\n",
    "\tplt.clf()\n",
    "\tplt.title(title)\n",
    "\tplt.bar(np.arange(e.shape[0]), x_stds, align='center')\n",
    "\tplt.draw()\n",
    "\tplt.savefig(write_dir + 'stds.png')\n",
    "\n",
    "if PLAY_ONLY:\n",
    "\tprint (\"Generating Songs...\")\n",
    "\tmake_rand_songs_normalized('', rand_vecs)\n",
    "\tfor i in range(20):\n",
    "\t\tx_test_song = x_train[i:i+1]\n",
    "\t\ty_song = model.predict(x_test_song, batch_size=BATCH_SIZE)[0]\n",
    "\t\tsamples_to_midi(y_song, 'gt' + str(i) + '.mid', 16)\n",
    "\texit(0)\n",
    "\t\t  \n",
    "print (\"Training...\")\n",
    "save_config()\n",
    "train_loss = []\n",
    "ofs = 0\n",
    "\n",
    "for iter in range(NUM_EPOCHS):\n",
    "\tif USE_EMBEDDING:\n",
    "\t\thistory = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n",
    "\telse:\n",
    "\t\tcur_ix = 0\n",
    "\t\tfor i in range(num_songs):\n",
    "\t\t\tend_ix = cur_ix + y_lengths[i]\n",
    "\t\t\tfor j in range(MAX_LENGTH):\n",
    "\t\t\t\tk = (j + ofs) % (end_ix - cur_ix)\n",
    "\t\t\t\ty_train[i,j] = y_samples[cur_ix + k]\n",
    "\t\t\tcur_ix = end_ix\n",
    "\t\tassert(end_ix == num_samples)\n",
    "\t\tofs += 1\n",
    "\n",
    "\t\thistory = model.fit(y_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n",
    "\n",
    "\tloss = history.history[\"loss\"][-1]\n",
    "\ttrain_loss.append(loss)\n",
    "\tprint (\"Train Loss: \" + str(train_loss[-1]))\n",
    "\t\n",
    "# \tif WRITE_HISTORY:\n",
    "# \t\tplotScores(train_loss, 'History/Scores.png', True)\n",
    "# \telse:\n",
    "\tplotScores(train_loss, 'Scores.png', True)\n",
    "\t\n",
    "\ti = iter + 1\n",
    "\tif i in [1, 3, 5, 8, 10, 13, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 450] or (i % 100 == 0):\n",
    "\t\twrite_dir = ''\n",
    "\t\tif WRITE_HISTORY:\n",
    "\t\t\t#Create folder to save models into\n",
    "\t\t\twrite_dir = 'History/e' + str(i)\n",
    "\t\t\tif not os.path.exists(write_dir):\n",
    "\t\t\t\tos.makedirs(write_dir)\n",
    "\t\t\twrite_dir += '/'\n",
    "\t\t\tmodel.save('History/model.h5')\n",
    "\t\telse:\n",
    "\t\t\tmodel.save('model.h5')\n",
    "\t\tprint (\"Saved\")\n",
    "\n",
    "\t\tif USE_EMBEDDING:\n",
    "\t\t\ty_song = model.predict(x_test_song, batch_size=BATCH_SIZE)[0]\n",
    "\t\telse:\n",
    "\t\t\ty_song = model.predict(y_test_song, batch_size=BATCH_SIZE)[0]\n",
    "\t\tsamples_to_pics(write_dir + 'test', y_song)\n",
    "\t\tsamples_to_midi(y_song, write_dir + 'test.mid', 16)\n",
    "\n",
    "\t\tmake_rand_songs_normalized(write_dir, rand_vecs)\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
